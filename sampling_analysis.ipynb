{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1558fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Creditcard_data.csv\")\n",
    "\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X, y)\n",
    "balanced_df = pd.concat([X_res, y_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04734c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling_techniques(data):\n",
    "    samples = []\n",
    "    n = len(data)\n",
    "    \n",
    "    # S1: Simple Random Sampling (Z=1.96, p=0.5, e=0.05)\n",
    "    s1_n = int((1.96**2 * 0.5 * 0.5) / (0.05**2))\n",
    "    samples.append(data.sample(n=s1_n, random_state=42))\n",
    "    \n",
    "    # S2: Systematic Sampling\n",
    "    interval = 5\n",
    "    samples.append(data.iloc[::interval])\n",
    "    \n",
    "    # S3: Stratified Sampling\n",
    "    samples.append(data.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=0.4, random_state=42)))\n",
    "    \n",
    "    # S4: Cluster Sampling\n",
    "    data['Cluster'] = np.repeat(range(10), len(data)//10 + 1)[:len(data)]\n",
    "    selected_clusters = [1, 5, 8]\n",
    "    samples.append(data[data['Cluster'].isin(selected_clusters)].drop('Cluster', axis=1))\n",
    "    data.drop('Cluster', axis=1, inplace=True)\n",
    "    \n",
    "    # S5: Bootstrap Sampling\n",
    "    samples.append(data.sample(frac=1.0, replace=True, random_state=42))\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# 4. Initialize Models \n",
    "models = {\n",
    "    \"M1\": LogisticRegression(max_iter=2000),\n",
    "    \"M2\": RandomForestClassifier(random_state=42),\n",
    "    \"M3\": SVC(random_state=42),\n",
    "    \"M4\": DecisionTreeClassifier(random_state=42),\n",
    "    \"M5\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "samples = get_sampling_techniques(balanced_df)\n",
    "results = {}\n",
    "\n",
    "# 5. Evaluate [cite: 21]\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    s_name = f\"Sampling{i}\"\n",
    "    results[s_name] = []\n",
    "    \n",
    "    X_s = sample.drop('Class', axis=1)\n",
    "    y_s = sample['Class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for m_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        results[s_name].append(acc * 100)\n",
    "\n",
    "# Create final table\n",
    "final_table = pd.DataFrame(results, index=models.keys())\n",
    "print(final_table)\n",
    "final_table.to_csv(\"submission_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
